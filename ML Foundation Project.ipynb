{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ML Foundation Project.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4hlztOhJyk93"
      },
      "source": [
        "### 1. Introduction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyTJUMPQy371",
        "colab_type": "text"
      },
      "source": [
        "Table of Content\n",
        "\n",
        "1 Problem Statement\n",
        "\n",
        "2 Data Loading and Description\n",
        "\n",
        "3 Exploratory Data Analysis\n",
        "\n",
        "4 Introduction to Linear Regression\n",
        "\n",
        "4.1 Linear Regression Equation with Errors in consideration\n",
        "\n",
        "4.1.1 Assumptions of Linear Regression\n",
        "\n",
        "4.2 Preparing X and y using pandas\n",
        "\n",
        "4.3 Splitting X and y into training and test datasets\n",
        "\n",
        "4.4 Linear regression in scikit-learn\n",
        "\n",
        "4.5 Interpreting Model Coefficients\n",
        "\n",
        "4.3 Using the Model for Prediction\n",
        "\n",
        "5 Model evaluation\n",
        "\n",
        "5.1 Model evaluation using metrics\n",
        "  \n",
        "5.2 Model Evaluation using Rsquared value.\n",
        "\n",
        "Feature Selection\n",
        "\n",
        "Handling Categorical Features \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6BHa8Z6vBR6",
        "colab_type": "text"
      },
      "source": [
        "### 1. Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sW-F_3hyyvN0"
      },
      "source": [
        "### 2. Data Loading and Description\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sql_zTV8xIb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Importing packages      \n",
        "import numpy as np                                                 # Implemennts milti-dimensional array and matrices\n",
        "import pandas as pd                                                # For data manipulation and analys\n",
        "### import pandas_profiling\n",
        "import matplotlib.pyplot as plt                                    # Plotting library for Python programming language and it's numerical mathematics extension NumPy\n",
        "import seaborn as sns                                              # Provides a high level interface for drawing attractive and informative statistical graphics\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "\n",
        "from subprocess import check_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wKCOS4WYPKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, absolute_import, print_function\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVRtKG0TxIb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Importing the Dataset\n",
        "\n",
        "candy_data = pd.read_csv(\"https://raw.githubusercontent.com/banduguide/URP_ML1/master/Candy_Data.csv\")     # Importing training dataset using pd.read_csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRTRBgvfxIcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 3. Preprocessing the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRzpc53mxIcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candy_data.head ()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QxbWQyFUBV4",
        "colab_type": "text"
      },
      "source": [
        "**3. Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMSpaAkyZkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candy_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WaqBBwTLN9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candy_data.describe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct5IL2LoYREL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candy_data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbw_ub6wOIE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candy_data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mMecE0OYxcj",
        "colab_type": "text"
      },
      "source": [
        "**Calculating and plotting heatmap correlation**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz5aM4ZhOSUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = candy_data.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr,vmax=.8,linewidth=.01, square = True, annot = True,cmap='YlGnBu',linecolor ='black')\n",
        "plt.title('Correlation between features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv5hP7LOPOOl",
        "colab_type": "text"
      },
      "source": [
        "**Observations:**\n",
        "1. fruity flaver is showing nagetive correlation with chocolate\n",
        "2. fruity flaver is showing good correlation with pluribus and haed texture,that means good combination for candy.\n",
        "3. caramel having negative correlation with fruity and hard texture\n",
        "4. caramel having good combination with chocoalte,nouguts ,crispedrice waffers and bar\n",
        "5. peanutyalmandy shows good correlation with chocolate,nouguts ,crispedrice waffers and bar\n",
        "6.  peanutyalmandy shows negative correlation with candy type products.\n",
        "7. crispedrice waffers shows good combination with chocolate ,caramel and bar.\n",
        "8. crispedrice waffers shows nagative correlation with nougat,peanutyalmandy,fruity, pluribus,hard candy type material.\n",
        "9. hard texture shows negative correlation with  chocoalte,nouguts ,crispedrice waffers and bar, peanutyalmandy,caramel\n",
        "10. hard texture shows good combination with fruity flaver\n",
        "11. chocolate shows high winpercentage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUe33Q1bpTMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, axes = plt.subplots(2, 2, figsize=(7, 7), sharex=True)                                      # Set up the matplotlib figure\n",
        "sns.despine(left=True)\n",
        "\n",
        "sns.distplot(candy_data.chocolate,color=\"blue\", ax=axes[0,0])\n",
        "sns.distplot(candy_data.caramel,color=\"red\", ax=axes[0,0)\n",
        "sns.distplot(candy_data.nougats,color=\"green\", ax=axes[0,0])\n",
        "sns.distplot(candy_data.winprice,color=\"magenta\", ax=axes[1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-IPWa2PtWTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "JG1 = sns.jointplot(\"chocolate\",\"winprice\", candy data=data, kind='scatterd')\n",
        "JG2 = sns.jointplot(\"caramle\", \"winprice\", data=candy_data, kind='reg')\n",
        "JG3 = sns.jointplot(\"fruity\", \"winprice\", data=candy_data, kind='reg')\n",
        "\n",
        "#subplots migration\n",
        "f = plt.figure()\n",
        "for J in [JG1,JG2,JG3]:\n",
        "    for A in J.fig.axes:\n",
        "        f._axstack.add(f._make_key(A), A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWW3zSAuZcJ_",
        "colab_type": "text"
      },
      "source": [
        "**Visualising Pairwise correlation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiM5hGYer94T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.pairplot(candy_data, size = 2, aspect = 1.5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj4atqPhZ1w5",
        "colab_type": "text"
      },
      "source": [
        "**4.2 Preparing X and y using pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRL8vtg8yBy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_cols = ['chocolate','fruity','caramel','peanutyalmondy','nougat','crispedricewafer','hard','bar','pluribus','sugarpercent','pricepercent']                # create a Python list of feature names\n",
        "X = candy_data[feature_cols]             # use the list to select a subset of the original DataFrame-+"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-z22SDyzvHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(X))\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S4PB4Tmz4kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = candy_data.winpercent\n",
        "Y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIh_sq0E3tfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(Y))\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63KhhCYEaz5Q",
        "colab_type": "text"
      },
      "source": [
        "**4.3 Splitting X and y into training and test datasets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvyqTFZn4mXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candy_data.to_csv(\"datasump.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyAub1685lpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split(X,Y):\n",
        "    return train_test_split(X, Y, test_size=0.20, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxXldivq5uDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test=split(X,Y)\n",
        "print('Train cases as below')\n",
        "print('X_train shape: ',X_train.shape)\n",
        "print('Y_train shape: ',Y_train.shape)\n",
        "print('\\nTest cases as below')\n",
        "print('X_test shape: ',X_test.shape)\n",
        "print('Y_test shape: ',Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_2vLTNw6EHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.to_csv(\"datasump_xtrain.csv\") \n",
        "X_test.to_csv(\"datasump_xtest.csv\") \n",
        "Y_train.to_csv(\"datasump_ytrain.csv\")\n",
        "Y_test.to_csv(\"datasump_ytest.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuOXMVgm6aB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTStC6Qo6NiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j5PRura88ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj__7R5I9AOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV-Vj_lgbH0n",
        "colab_type": "text"
      },
      "source": [
        "**4.4 Linear regression in scikit-learn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb4vrSMa7A9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61zeAVfjiqJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-uEoGgmN3Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg.fit(X_train, Y_train)  # this is the trianing code. all learning is happening here\\"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpwziy4GODYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBrJKIJIOGxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_2hRIIaN78f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loNG7AZhO75_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[X_test.iloc[5]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3PAlvMB_H0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg.predict([X_test.iloc[5]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh1-wPO2_ODi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2DAC_W7Oo4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = linreg.predict([X_test.iloc[5]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM4mCb5xPBst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emG9Cr1U-WAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDmYYIy9-RBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg.predict([X_test.iloc[1]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vS6zNdyPCXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred - Y_test.iloc[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0WpmOrtPmnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ-u48EVPpML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg.predict(X_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meJqo2W1PtrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_test = linreg.predict(X_test) \n",
        "RMSE_test = (metrics.mean_squared_error(Y_test,Y_pred_test))                          # compute the RMSE of our predictions\n",
        "print('RMSE for the test set is {}'.format(RMSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L05i6C-Fbcep",
        "colab_type": "text"
      },
      "source": [
        "When you do scaling outside linear regression, the RMSE calculations shows scaled version of devaition. You would have to rescale them if you want to know actual deviation with respect to actual scale of Y (Sales)\n",
        "When you do scaling inside LR Function, it scales the data to fit the line, but it automatically scales the RMSE back to original Y (Sales)\n",
        "This only applies to LR "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB8T-DY8bvLx",
        "colab_type": "text"
      },
      "source": [
        "Scaling --- IT scales the value into specific range\n",
        "\n",
        "2 Processs for Accuracy Calcualtions\n",
        "\n",
        "1) Y_Pred Y_Test Manual Scaling 2) Y_Pred Y_Test -> [Normalize=True] Algo Scaling 3) Y_Pred Y_Test -> ; same result as 1. ; Algo Scaling 4) Y_Pred Y_Test ->; same result as 1 [Algo Scaling]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj_zcN9qb29J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(pd.DataFrame(Y_test))\n",
        "scaler.transform(pd.DataFrame(Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljcwdbR4rKlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl7YijrXcXYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF-Bn8AEgx-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred --- is also going to be scaled values \n",
        "Deviation -- y_pred & Y_test  --> scaled "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uowcO0eUcg45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred --- Non Scaling \n",
        "Y_pred with Y_test --> Non_Scaled RMSE \n",
        "\n",
        "\n",
        "Added Parameter ---> Normalize=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQvKnMDsdh8N",
        "colab_type": "text"
      },
      "source": [
        "if you plan to use scaling from Algorithm, don't scale before.\n",
        "when you don't pass any parameters to algo, it means you are working on default/baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23CrxgBYdkW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdcc95E8dyAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWkq795Ld5Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression(normalize=False, fit_intercept=False)\n",
        "linreg.fit(X_train, Y_train) \n",
        "Y_pred_test = linreg.predict(X_test)   \n",
        "# make predictions on the testing set\n",
        "RMSE_test = (metrics.mean_squared_error(Y_test, Y_pred_test)) # compute the RMSE of our predictions\n",
        "print('RMSE for the test set is {}'.format(RMSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI970Xa6eSZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO_apsHCY_m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression(normalize=True)\n",
        "linreg.fit(X_train, Y_train) \n",
        "Y_pred_test = linreg.predict(X_test)   \n",
        "# make predictions on the testing set\n",
        "RMSE_test = (metrics.mean_squared_error(Y_test, Y_pred_test)) # compute the RMSE of our predictions\n",
        "print('RMSE for the test set is {}'.format(RMSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i6mzzBcVQkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression(normalize=False)\n",
        "linreg.fit(X_train, Y_train) \n",
        "Y_pred_test = linreg.predict(X_test)   \n",
        "# make predictions on the testing set\n",
        "RMSE_test = (metrics.mean_squared_error(Y_test, Y_pred_test)) # compute the RMSE of our predictions\n",
        "print('RMSE for the test set is {}'.format(RMSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0SDuAGux1Bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is after doing manual scaling. Make sure the X_train and Y_train gets scaled before sending to this function \n",
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train,Y_train) \n",
        "Y_pred_test = linreg.predict(X_test)   \n",
        "\n",
        "                                                # make predictions on the testing set\n",
        "RMSE_test = (metrics.mean_squared_error(Y_test, Y_pred_test))                          # compute the RMSE of our predictions\n",
        "print('RMSE for the test set is {}'.format(RMSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6goTknMchph",
        "colab_type": "text"
      },
      "source": [
        "# when gridsearch does the training, it create its own Train & Test. Make sure, wheever you do GridSearch, use random_seed "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtpvQwxOwkri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# define the parameters , it should always be a dictionary \n",
        "parameters = {'normalize':[True,False], 'copy_X':[True, False], 'fit_intercept':[True,False]}\n",
        "linreg = LinearRegression() # this the model on which i would want to experiment \n",
        "\n",
        "# Call the GridSearch Class, Pass the model and parameter \n",
        "linreg = GridSearchCV(linreg,parameters)\n",
        "\n",
        "\n",
        "linreg.fit(X_train, Y_train)                                                           # fit the model to the training data (learn the coefficients)\n",
        "#, So internal Train test get created on this X_Train & Y_Train 80,20% \n",
        "# So, it creates new 80,20 split from the previous(global) 80% "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb871Ap9c-K1",
        "colab_type": "text"
      },
      "source": [
        "# This best_scaore_ gives you the RMSE of internal Train Test set of GridSearch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6IuWamVG7u5",
        "colab_type": "text"
      },
      "source": [
        "# always fight for best stable model and not accurate model. -> Real World/Depolyment Prospective "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZkUAWNSb5hQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Mean cross-validated score of the best_estimator : \", linreg.best_score_)  \n",
        "# Of the internal Test set which is created out of 80% "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGEXqXwPbxxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrHnloX6bqw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)\n",
        "linreg.fit(X_train, Y_train)\n",
        "Y_pred_test = linreg.predict(X_test)                                                   # make predictions on the testing set\n",
        "\n",
        "RMSE_test = (metrics.mean_squared_error(Y_test, Y_pred_test))                          # compute the RMSE of our predictions\n",
        "print('RMSE for the test set is {}'.format(RMSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_H5_ruOwkrl",
        "colab_type": "text"
      },
      "source": [
        "### 4.5 Interpreting Model Coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgMA-Orjsn4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Intercept:',linreg.intercept_)                                           # print the intercept \n",
        "print('Coefficients:',linreg.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS39LsdssuN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm_SMdddsyN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linreg.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG33xOh6s05d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_cols.insert(0,'Intercept')\n",
        "coef = linreg.coef_.tolist()\n",
        "coef.insert(0, linreg.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjACCYpzs4L7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eq1 = zip(feature_cols, coef)\n",
        "\n",
        "for c1,c2 in eq1:\n",
        "    print(c1,c2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GSEr5XotHZI",
        "colab_type": "text"
      },
      "source": [
        "### 4.6 Using the Model for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95MgUrj2s-zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_train = linreg.predict(X_train)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oJXEsXwtXrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred_test = linreg.predict(X_test)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwUqEECWwkrz",
        "colab_type": "text"
      },
      "source": [
        "## 5. Model evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy6dJk2Nwkr0",
        "colab_type": "text"
      },
      "source": [
        "### 5.1 Model Evaluation using __metrics.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rqJBegJwkrk",
        "colab_type": "text"
      },
      "source": [
        "<a id=section405></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsOhlhzgLpJY",
        "colab_type": "text"
      },
      "source": [
        "The difference between Train Accuracy and Test Accuracy should be least for a good Model\n",
        "Train Accuracy. y_train ~~ model.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gujP6ekfLSoJ",
        "colab_type": "text"
      },
      "source": [
        "Mean Squared Error (MSE) is the mean of the squared errors:\n",
        "1n∑i=1n(yi−y^i)2\n",
        "\n",
        "Computing the MSE for our Sales predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRc5-6AlTPNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAE_train = metrics.mean_absolute_error(Y_train, Y_pred_train)\n",
        "MAE_test = metrics.mean_absolute_error(Y_test, Y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bpi9bw2TgXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('MAE for training set is {}'.format(MAE_train))\n",
        "print('MAE for test set is {}'.format(MAE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9e2yCrjLBWb",
        "colab_type": "text"
      },
      "source": [
        "oot Mean Squared Error (RMSE) is the square root of the mean of the squared errors:\n",
        "\n",
        "1n∑i=1n(yi−y^i)2−−−−−−−−−−−−√\n",
        "\n",
        "Computing the RMSE for our Sales predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBbgPjOHTxYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_train = metrics.mean_squared_error( Y_train, Y_pred_train)\n",
        "MSE_test = metrics.mean_squared_error(Y_test, Y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUp0QAr2T5Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('MSE for training set is {}'.format(MSE_train))\n",
        "print('MSE for test set is {}'.format(MSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsiYuqDqgnxu",
        "colab_type": "text"
      },
      "source": [
        "**5.2 Model Evaluation using Rsquared value.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI8VBSSKiqk9",
        "colab_type": "text"
      },
      "source": [
        "There is one more method to evaluate linear regression model and that is by using the Rsquared value.\n",
        "\n",
        "R-squared is the proportion of variance explained, meaning the proportion of variance in the observed data that is explained by the model, or the reduction in error over the null model. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)\n",
        "\n",
        "R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model. But there is one shortcoming of Rsquare method and that is R-squared will always increase as you add more features to the model, even if they are unrelated to the response. Thus, selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model.\n",
        "\n",
        "There is alternative to R-squared called adjusted R-squared that penalizes model complexity (to control for overfitting).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgGQhniSnphd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Yhat = linreg.predict(X_train)\n",
        "SS_Residual = sum((Y_train-yhat)**2)\n",
        "SS_Total = sum((Y_train-np.mean(Y_train))**2)\n",
        "r_squared = 1 - (float(SS_Residual))/SS_Total\n",
        "adjusted_r_squared = 1 - (1-r_squared)*(len(Y_train)-1)/(len(Y_train)-X_train.shape[1]-1)\n",
        "print(r_squared, adjusted_r_squared)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X917BKQjoYRh",
        "colab_type": "text"
      },
      "source": [
        "6. Feature Selection\n",
        "At times some features do not contribute much to the accuracy of the model, in that case its better to discard those features.\n",
        "Let's check whether \"newspaper\" improve the quality of our predictions or not.\n",
        "To check this we are going to take all the features other than \"newspaper\" and see if the error (RMSE) is reducing or not.\n",
        "Also Applying Gridsearch method for exhaustive search over specified parameter values of estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-oSlQpEnl32",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RvNmw71UJ-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# linear regression always work on numerical continuous. \n",
        "# the area column is categorical column - nonOrdinal \n",
        "  # possible solution -> you conver this to discreat numeircal ; 0,1,2, \n",
        "  # the actual solution is to convert numeical descrete to Dummy Variable \n",
        "  # Categrical (single col) --> Numerical Discreate (single col) --> Dummy Variable (which projects the categories into axis of vector space) (multiple col)\n",
        "  # For N Categories, N columns will be created in Dummies. You always need N-1 columns to represent whole data\n",
        "  # If the inference is important, Use N columns rather than N-1.\n",
        "  # by default, always do N columns in Dummy. \n",
        "\n",
        "\n",
        "  # the data sent to model should always be constint: \n",
        "     # The data type representation should be same - either all should be numerical cont, or all should be category ?\n",
        "     # If it is numerical cont, then make sure that they are scaled.  \n",
        "     # Goal is to to convert all data types to Numerical cont: \n",
        "        # String cateogry -> get_dummies \n",
        "        # numerical discreate --> get_dummies [peopel are always confused on this; \n",
        "                  #we call something as discreate, when the unique of that column is way lesser than total values; uniq(col1)<<<<<total values (col)]\n",
        "     # Goal is to convert everything to category:  (Don't do this for LR)\n",
        "        # Numerical Cont data --> You take ranges (bins)  and create groups \n",
        "        # pd.cut(data['Sales'], bins=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uuX8StDobJu",
        "colab_type": "text"
      },
      "source": [
        " Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6QvnEmAEqZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(123456)                                                # set a seed for reproducibility\n",
        "nums = np.random.ran (len (candy_data))\n",
        "mask_chocolate = (nums > 0.33) & (nums < 0.66)                       # assign roughly one third of observations to each group\n",
        "mask_candy = nums < 0.33\n",
        "data.loc[mask_chocolate, 'catagory'] = 'chocolate'\n",
        "data.loc[mask_candy, 'catagory'] = 'candy'\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdiNO7ZDi7Y-",
        "colab_type": "text"
      },
      "source": [
        "7. Handling Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aynPqxQTomol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " feature_cols = ['chocolate','fruity','caramel','peanutyalmondy','nougat','crispedricewafer','hard','bar','pluribus','sugarpercent','pricepercent']                                                          # create a Python list of feature names\n",
        "X = candy_data[feature_cols]  \n",
        "Y = candy_data.winpercent\n",
        "\n",
        "X_train, X_test, Y_train, Y_test=split(X,Y)\n",
        "\n",
        "linreg = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)\n",
        "linreg.fit(X_train, Y_train)\n",
        "Y_pred_test = linreg.predict(X_test)                                                   # make predictions on the testing set\n",
        "\n",
        "RMSE_test = (metrics.mean_squared_error(Y_test, Y_pred_test))                          # compute the RMSE of our predictions\n",
        "print('RMSE for the test set is {}'.format(RMSE_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_U2mIKzqL_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Intercept:',linreg.intercept_)                                           # print the intercept \n",
        "print('Coefficients:',linreg.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG8TiFxAqZHD",
        "colab_type": "text"
      },
      "source": [
        "more the variables in the model, more uncertainity you will carry while prediction. So the goal is always to reduce the dependency a model has on number of columns.\n",
        "Feature Selection\n",
        "# Imporves accuracy \n",
        "# Imporoves Time \n",
        "# Reduces uncertainity \n",
        "# Reduces biases \n",
        "Only do feature selection/susbset, if you have a mathematical/quantifyable way of knowing if that feature is impr or not. Just like, in LR, we saw that Newspaper isn't giving us good dependency and was acting as noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBhb1gO9qrXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oUh4lYjqszT",
        "colab_type": "text"
      },
      "source": [
        "Before doing feature selection RMSE for the test dataset was 0.271.\n",
        "After discarding 'newspaper' column, RMSE comes to be 0.072.\n",
        "As you can see there is significant improvement in the quality, therefore, the 'newspaper' column should be discarded. But if in some other case if there is no significant decrease in the RMSE, then you must keep that feature.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kol5Cz9WrN0r",
        "colab_type": "text"
      },
      "source": [
        "7. Handling Categorical Features\n",
        "Let's create a new feature called Area, and randomly assign observations to be rural, suburban, or urban :\n",
        "\n",
        "[ ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIWhb17rrs-5",
        "colab_type": "text"
      },
      "source": [
        " linear regression always work on numerical continuous. \n",
        "# the area column is categorical column - nonOrdinal \n",
        "  # possible solution -> you conver this to discreat numeircal ; 0,1,2, \n",
        "  # the actual solution is to convert numeical descrete to Dummy Variable \n",
        "  # Categrical (single col) --> Numerical Discreate (single col) --> Dummy Variable (which projects the categories into axis of vector space) (multiple col)\n",
        "  # For N Categories, N columns will be created in Dummies. You always need N-1 columns to represent whole data\n",
        "  # If the inference is important, Use N columns rather than N-1.\n",
        "  # by default, always do N columns in Dummy. \n",
        "\n",
        "\n",
        "  # the data sent to model should always be constint: \n",
        "     # The data type representation should be same - either all should be numerical cont, or all should be category ?\n",
        "     # If it is numerical cont, then make sure that they are scaled.  \n",
        "     # Goal is to to convert all data types to Numerical cont: \n",
        "        # String cateogry -> get_dummies \n",
        "        # numerical discreate --> get_dummies [peopel are always confused on this; \n",
        "                  #we call something as discreate, when the unique of that column is way lesser than total values; uniq(col1)<<<<<total values (col)]\n",
        "     # Goal is to convert everything to category:  (Don't do this for LR)\n",
        "        # Numerical Cont data --> You take ranges (bins)  and create groups \n",
        "        # pd.cut(data['Sales'], bins=6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTugbMEUrzHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(123456)                                                # set a seed for reproducibility\n",
        "nums = np.random.rand(len(candy_data))\n",
        "mask_chocolate = (nums > 0.33) & (nums < 0.66)                         # assign roughly one third of observations to each group\n",
        "mask_candy= (nums < 0 )\n",
        "data.loc[compititor type] = 'chocolate'\n",
        "data.loc[mask_chocolate, 'compititor type'] = 'chocolate'\n",
        "data.loc[mask_candy, 'compititor type'] = 'candy'\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doD0RAECXdCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.cut(candy_data['winpercent'], bins=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuTpyVPLudDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd(['winpercent'].isnull().sort_values(descending=false)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}